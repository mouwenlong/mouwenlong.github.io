<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Invited talks</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Wenlong Mou</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="experiences.html">Experiences</a></div>
<div class="menu-item"><a href="talks.html" class="current">Talks</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Invited talks</h1>
</div>
<h2>Upcoming talks</h2>
<ul>
<li><p>Policy Evaluation With General Function Approximation: Efficient Algorithms And Instance-dependent Guarantees, <i>INFORMS Annual Meeting</i>, Phoenix, Oct 2023</p>
</li>
</ul>
<h2>Past talks</h2>
<ul>
<li><p>Statistical theory for reinforcement learning: Oracle inequalities, Markov chains, and stochastic approximation, <i>Young Researchers Workshop</i>, Cornell University, Oct 2022</p>
</li>
<li><p>Optimal and Instance-dependent Guarantees for Markovian Linear Stochastic Approximation, APS student paper competition at <i>INFORMS Annual Meeting</i>, Indianapolis, Oct 2022</p>
</li>
<li><p>On The Statistical Complexity Of Reinforcement Learning With Function Approximation, <i>INFORMS Annual Meeting</i>, Indianapolis, Oct 2022</p>
</li>
<li><p>Rethinking semi-parametric efficiency for off-policy estimation: a non-asymptotic perspective, <i>BLISS seminar</i>, UC Berkeley, Oct 2022</p>
</li>
<li><p>Optimal variance-reduced stochastic approximation in Banach spaces, <i>Applied and Computational Math seminar</i>, Georgia Institute of Technology, Nov 2022</p>
</li>
<li><p>Optimal algorithms for reinforcement learning: Oracle inequalities, Markov chains, and stochastic approximation, <i>International Conference on Continuous Optimization</i>, Lehigh University, July 2022</p>
</li>
<li><p>Statistical theory for reinforcement learning: Oracle inequalities, Markov chains, and stochastic approximation, <i>Neyman seminar</i>, Department of Statistics, UC Berkeley, January 2022</p>
</li>
<li><p>High-Order Langevin diffusion yields an accelerated MCMC algorithm, Simons Institute program on <i>Geometric Methods in Optimization and Sampling</i>, October 2021</p>
</li>
<li><p>Optimal oracle inequalities for projected fixed-point equations, Machine Learning reading group, UT Austin, September 2021</p>
</li>
<li><p>On the sample complexity of reinforcement learning with policy space generalization, Simons Institute, reinforcement learning theory student seminar, December 2020</p>
</li>
<li><p>Langevin diffusions in modern statistical learning: discretization, sampling, and posterior concentration, statistics reading group, University of Wisconsin, Madison, July 2020</p>
</li>
<li><p>High-Order Langevin diffusion yields an accelerated MCMC algorithm, <i>ACO student seminar</i>, Georgia Institute of Technology, October 2019</p>
</li>
<li><p>Generalization bounds of SGLD for non-convex learning: two theoretical viewpoints, Simons Institute, deep learning student seminar, October 201</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
