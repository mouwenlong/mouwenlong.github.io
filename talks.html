<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Invited talks</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Wenlong Mou</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="experiences.html">Experiences</a></div>
<div class="menu-item"><a href="talks.html" class="current">Talks</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Invited talks</h1>
</div>
<h2>Upcoming talks</h2>
<ul>
<li><p>Structure-driven design of reinforcement learning algorithms: a tale of two estimators, Northwestern University, Nov 2024
</p>
</li>
<li><p>Continuous-time reinforcement learning: blessings of diffusion structures and high-order approximations, <i>CMS Winter Meeting</i>, Vancouver, Dec 2024
</p>
</li>
</ul>
<h2>Past talks</h2>
<ul>
<li><p>Structure-driven design of reinforcement learning algorithms: a tale of bootstrapping and rollout, Georgia Institute of Technology, Nov 2024
</p>
</li>
<li><p>To bootstrap or to rollout? An optimal and adaptive interpolation, <i>INFORMS Annual Meeting</i>, Seattle, Oct 2024
</p>
</li>
<li><p>A decorrelation method for general regression adjustment in randomized experiments, <i>IMS-Bernoulli World Congress</i>, Bochum, Aug 2024
</p>
</li>
<li><p>Optimal stochastic approximation under general norms with applications to reinforcement learning, Shanghai Jiaotong University, July 2024
</p>
</li>
<li><p>To bootstrap or to rollout? An optimal and adaptive interpolation, <i>International Conference on Frontiers of Data Science</i>, Hangzhou, Jul 2024
</p>
</li>
<li><p>A decorrelation method for general regression adjustment in randomized experiments, Banff International Research Station, Feb 2024
</p>
</li>
<li><p>Policy Evaluation With General Function Approximation: Efficient Algorithms And Instance-dependent Guarantees, <i>INFORMS Annual Meeting</i>, Phoenix, Oct 2023
</p>
</li>
<li><p>Statistical theory for reinforcement learning: Oracle inequalities, Markov chains, and stochastic approximation, <i>Young Researchers Workshop</i>, Cornell University, Oct 2022
</p>
</li>
<li><p>Optimal and Instance-dependent Guarantees for Markovian Linear Stochastic Approximation, APS student paper competition at <i>INFORMS Annual Meeting</i>, Indianapolis, Oct 2022
</p>
</li>
<li><p>On The Statistical Complexity Of Reinforcement Learning With Function Approximation, <i>INFORMS Annual Meeting</i>, Indianapolis, Oct 2022
</p>
</li>
<li><p>Rethinking semi-parametric efficiency for off-policy estimation: a non-asymptotic perspective, <i>BLISS seminar</i>, UC Berkeley, Oct 2022
</p>
</li>
<li><p>Optimal variance-reduced stochastic approximation in Banach spaces, <i>Applied and Computational Math seminar</i>, Georgia Institute of Technology, Nov 2022
</p>
</li>
<li><p>Optimal algorithms for reinforcement learning: Oracle inequalities, Markov chains, and stochastic approximation, <i>International Conference on Continuous Optimization</i>, Lehigh University, July 2022
</p>
</li>
<li><p>Statistical theory for reinforcement learning: Oracle inequalities, Markov chains, and stochastic approximation, <i>Neyman seminar</i>, Department of Statistics, UC Berkeley, January 2022
</p>
</li>
<li><p>High-Order Langevin diffusion yields an accelerated MCMC algorithm, Simons Institute program on <i>Geometric Methods in Optimization and Sampling</i>, October 2021</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
