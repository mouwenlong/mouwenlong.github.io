<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Papers</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Wenlong Mou</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="experiences.html">Experiences</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Papers</h1>
</div>
<ul>
<li><p><a href="https://arxiv.org/abs/2411.09731" target=&ldquo;blank&rdquo;>To bootstrap or to rollout? An optimal and adaptive interpolation</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Jian Qian (equal contribution)
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2407.05966v1" target=&ldquo;blank&rdquo;>On Bellman equations for continuous-time policy evaluation I: discretization and approximation</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Yuhua Zhu (equal contribution)
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2311.10076" target=&ldquo;blank&rdquo;>A decorrelation method for general regression adjustment in randomized experiments</a>
</p>
<ul>
<li><p>Fangzhou Su, <b>Wenlong Mou (equal contribution)</b>, Peng Ding, Martin J. Wainwright
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2411.02909" target=&ldquo;blank&rdquo;>When is it worthwhile to jackknife? Breaking the quadratic barrier for Z-estimators</a>
</p>
<ul>
<li><p>Licong Lin, Fangzhou Su, <b>Wenlong Mou</b>, Peng Ding, Martin J. Wainwright
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2012.05299" target=&ldquo;blank&rdquo;>Optimal oracle inequalities for solving projected fixed-point equations, with applications to policy evaluation</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Ashwin Pananjady, and Martin Wainwright
</p>
</li>
<li><p>Published at <i>Mathematics of Operations Research</i>, article in advance, 2022+
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2301.06240" target=&ldquo;blank&rdquo;>Kernel-based off-policy estimation without overlap: Instance optimality beyond semiparametric efficiency</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Peng Ding, Martin Wainwright, and Peter Bartlett
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2209.13075" target=&ldquo;blank&rdquo;>Off-policy Estimation of Linear Functionals:
Non-asymptotic Theory for Semi-parametric Efficiency</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Martin Wainwright, and Peter Bartlett
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2112.12770" target=&ldquo;blank&rdquo;>Optimal and Instance-dependent Guarantees for Markovian Linear Stochastic Approximation</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Ashwin Pananjady, Martin Wainwright, and Peter Bartlett
</p>
</li>
<li><p>Selected as a finalist for INFORMS APS student paper competition, 2022
</p>
</li>
<li><p>Extended abstract appeared at <a href="https://proceedings.mlr.press/v178/mou22a/mou22a.pdf" target=&ldquo;blank&rdquo;><i>COLT</i> 2022</a>
</p>
</li>
<li><p>Accepted to <i>Mathematical Statistics and Learning</i>, 2023+
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1909.00966" target=&ldquo;blank&rdquo;>A Diffusion Process Perspective on Posterior Contraction Rates for Parameters</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Nhat Ho, Martin Wainwright, Peter Bartlett, and Michael Jordan
</p>
</li>
<li><p>Accepted to <i>SIAM Journal on Mathematics of Data Science</i>, 2023+
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2201.08518" target=&ldquo;blank&rdquo;>Optimal Variance-reduced Stochastic Approximation in Banach Spaces</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Koulik Khamaru (equal contribution), Martin Wainwright, Peter Bartlett, and Michael Jordan
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2303.17102" target=&ldquo;blank&rdquo;>When is the estimated propensity score better? High-dimensional analysis and bias correction</a>
</p>
<ul>
<li><p>Fangzhou Su, <b>Wenlong Mou (equal contribution)</b>, Peng Ding, Martin Wainwright
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://proceedings.mlr.press/v178/li22a/li22a.pdf" target=&ldquo;blank&rdquo;>ROOT-SGD: Sharp Nonasymptotics and Asymptotic Efficiency in a Single Algorithm</a>
</p>
<ul>
<li><p>Chris Junchi Li, <b>Wenlong Mou (equal contribution)</b>, Martin Wainwright, and Michael Jordan
</p>
</li>
<li><p>In proceedings of <a href="https://proceedings.mlr.press/v178/li22a/li22a.pdf" target=&ldquo;blank&rdquo;><i>COLT</i> 2022</a>
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://projecteuclid.org/journals/bernoulli/volume-28/issue-3/Improved-bounds-for-discretization-of-Langevin-diffusions--Near-optimal/10.3150/21-BEJ1343.short" target=&ldquo;blank&rdquo;>Improved Bounds for Discretization of Langevin Diffusions: Near-optimal rates without Convexity</a>       
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Nicolas Flammarion, Martin Wainwright, and Peter Bartlett
</p>
</li>
<li><p>Published at <a href="https://projecteuclid.org/journals/bernoulli/volume-28/issue-3/Improved-bounds-for-discretization-of-Langevin-diffusions--Near-optimal/10.3150/21-BEJ1343.short" target=&ldquo;blank&rdquo;><i>Bernoulli</i></a> 28.3 (2022): 1577-1601
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://jmlr.org/papers/v22/20-576.html" target=&ldquo;blank&rdquo;>High-Order Langevin Diffusion Yields an Accelerated MCMC Algorithm</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Yi-An Ma (equal contribution), Martin Wainwright, Peter Bartlett, and Michael Jordan
</p>
</li>
<li><p>Published at <a href="https://jmlr.org/papers/v22/20-576.html" target=&ldquo;blank&rdquo;><i>Journal of Machine Learning Research</i></a>, 22(42):1-41, 2021
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1910.00551" target=&ldquo;blank&rdquo;>An Efficient Sampling Algorithm for Non-smooth Composite Potentials</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Nicolas Flammarion, Martin Wainwright, and Peter Bartlett
</p>
</li>
<li><p>Published at <i>Journal of Machine Learning Research</i>, to appear (2022+)
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2008.07353" target=&ldquo;blank&rdquo;>On the Sample Complexity of Reinforcement Learning with Policy Space Generalization</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Zheng Wen, Xi Chen
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://proceedings.mlr.press/v125/mou20a.html" target=&ldquo;blank&rdquo;>On Linear Stochastic Approximation: Fine-grained Polyak&ndash;Ruppert and Non-Asymptotic Concentration</a>    
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Chris Junchi Li, Martin Wainwright, Peter Bartlett, and Michael Jordan
</p>
</li>
<li><p>In proceedings of <a href="https://proceedings.mlr.press/v125/mou20a.html" target=&ldquo;blank&rdquo;><i>COLT</i> 2020</a>
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1912.05153" target=&ldquo;blank&rdquo;>Sampling for Bayesian Mixture Models: MCMC with Polynomial-time Mixing</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Nhat Ho, Martin Wainwright, Peter Bartlett, and Michael Jordan
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://proceedings.mlr.press/v75/mou18a.html" target=&ldquo;blank&rdquo;>Generalization Bounds of SGLD for Non-convex Learning: Two Theoretical Viewpoints</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Liwei Wang, Xiyu Zhai, and Kai Zheng (alphabetical order)
</p>
</li>
<li><p>In proceedings of <a href="https://proceedings.mlr.press/v75/mou18a.html" target=&ldquo;blank&rdquo;><i>COLT</i> 2018</a>
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://proceedings.mlr.press/v80/mou18a.html" target=&ldquo;blank&rdquo;>Dropout Training, Adaptive Regularization and Generalization Error Bounds</a>
</p>
<ul>
<li><p><b>Wenlong Mou</b>, Yuchen Zhou, Jun Gao, and Liwei Wang
</p>
</li>
<li><p>In proceedings of <a href="https://proceedings.mlr.press/v80/mou18a.html" target=&ldquo;blank&rdquo;><i>ICML</i> 2018</a>
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://proceedings.mlr.press/v70/balcan17a.html" target=&ldquo;blank&rdquo;>Differentially Private Clustering in High-dimensional Euclidean Spaces</a>
</p>
<ul>
<li><p>Maria-Florina Balcan, Travis Dick, Yingyu Liang, <b>Wenlong Mou</b>, and Hongyang Zhang (alphabetical order)
</p>
</li>
<li><p>In proceedings of <a href="https://proceedings.mlr.press/v70/balcan17a.html" target=&ldquo;blank&rdquo;><i>ICML</i> 2017</a>
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="http://proceedings.mlr.press/v70/zheng17c/zheng17c.pdf" target=&ldquo;blank&rdquo;>Collect at Once, Use Effectively: Making Non-interactive Locally Private Learning Possible</a>
</p>
<ul>
<li><p>Kai Zheng, <b>Wenlong Mou</b>, Liwei Wang
</p>
</li>
<li><p>In proceedings of <a href="http://proceedings.mlr.press/v70/zheng17c/zheng17c.pdf" target=&ldquo;blank&rdquo;><i>ICML</i> 2017</a>
</p>
</li>
</ul>

</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
